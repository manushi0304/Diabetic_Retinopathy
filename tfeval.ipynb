{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manushi0304/Diabetic_Retinopathy/blob/main/tfeval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGnZxw7vcL6N",
        "outputId": "f1be784b-0b3b-4c12-ce7f-19f5acb55608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Using BASE = /content/drive/MyDrive/DiabeticProject\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/DiabeticProject\"\n",
        "print(\"Using BASE =\", BASE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnrDFGCAcTYA",
        "outputId": "719a5a21-4876-4b02-9011-fe409e031ac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BASE: /content/drive/MyDrive/DiabeticProject\n",
            "=== TFLite models (.tflite) ===\n",
            "/content/drive/MyDrive/DiabeticProject/hybrid_models/EfficientNetV2B0_fp16_FE_HEAD_from_KNN_fused_fp32.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/hybrid_models/EfficientNetV2B0_fp16_FE_HEAD_from_RandomForest_fused_fp32.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/hybrid_models/EfficientNetV2B0_fp16_FE_HEAD_from_SVM_RBF_fused_fp32.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/hybrid_models/EfficientNetV2B0_fp16_FE_HEAD_fused_fp32.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/tflite/EfficientNetV2B0_model_fp16.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/tflite/EfficientNetV2B0_model_fp32.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/tflite/EfficientNetV2B0_model_int8.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/tflite/InceptionV3_model_fp16.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/tflite/InceptionV3_model_fp32.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/tflite/InceptionV3_model_int8.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/tflite/MobileNetV2_model_fp16.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/tflite/MobileNetV2_model_fp32.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/tflite/MobileNetV2_model_int8.tflite\n",
            "\n",
            "=== Parent models (.keras / .h5) ===\n",
            "/content/drive/MyDrive/DiabeticProject/hybrid_models/EfficientNetV2B0_fp16_FE_feature_extractor.keras\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/EfficientNetV2B0_single/latest_model.keras\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/EfficientNetV2B0_single/latest.weights.h5\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/EfficientNetV2B0_single_split.keras\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/InceptionV3_single/latest_model.keras\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/InceptionV3_single_split.keras\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/MobileNetV2_single/latest_model.keras\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/MobileNetV2_single_split.keras\n",
            "\n",
            "=== CSVs (with sizes) ===\n",
            "/content/drive/MyDrive/DiabeticProject/hybrid_models/EfficientNetV2B0_fp16_FE_ALL_heads_latency.csv\t1 KB\n",
            "/content/drive/MyDrive/DiabeticProject/hybrid_models/EfficientNetV2B0_fp16_FE_ALL_TFLite_hybrid_latency.csv\t1 KB\n",
            "/content/drive/MyDrive/DiabeticProject/hybrid_models/hybrid_test_metrics.csv\t2 KB\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/all_models_train_accuracy_first40_summary.csv\t1 KB\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/all_models_train_accuracy_summary.csv\t1 KB\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/all_models_val_accuracy_summary.csv\t1 KB\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/all_models_val_f1_summary.csv\t1 KB\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/all_models_val_metric_summary.csv\t1 KB\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/DenseNet121_single/training_log.csv\t7 KB\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/EfficientNetV2B0_single/training_log.csv\t7 KB\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/hybrid_size_replace_allheads_effv2b0.csv\t2 KB\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/InceptionV3_single/training_log.csv\t7 KB\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/MobileNetV2_single/training_log.csv\t8 KB\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/NasNet_single/training_log.csv\t7 KB\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/ResNet_single/training_log.csv\t7 KB\n",
            "/content/drive/MyDrive/DiabeticProject/test.csv\t305 KB\n",
            "/content/drive/MyDrive/DiabeticProject/tflite_eval_summary.csv\t2 KB\n",
            "/content/drive/MyDrive/DiabeticProject/tflite_eval_summary_sample10.csv\t2 KB\n",
            "/content/drive/MyDrive/DiabeticProject/training_logs/all_models_training_log.csv\t1 KB\n",
            "/content/drive/MyDrive/DiabeticProject/training_logs/EfficientNetV2B0_training_log.csv\t1 KB\n",
            "/content/drive/MyDrive/DiabeticProject/training_logs/final_test_results.csv\t3 KB\n",
            "/content/drive/MyDrive/DiabeticProject/training_logs/InceptionV3_training_log.csv\t1 KB\n",
            "/content/drive/MyDrive/DiabeticProject/training_logs/MobileNetV2_training_log.csv\t1 KB\n",
            "\n",
            "=== Image folders (top 50 by file count) ===\n",
            "      7 /content/drive/MyDrive/DiabeticProject/saved_models\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "BASE=\"/content/drive/MyDrive/DiabeticProject\"\n",
        "\n",
        "echo \"BASE: $BASE\"\n",
        "\n",
        "echo \"=== TFLite models (.tflite) ===\"\n",
        "find \"$BASE\" -type f -name \"*.tflite\" | sort || true\n",
        "\n",
        "echo\n",
        "echo \"=== Parent models (.keras / .h5) ===\"\n",
        "find \"$BASE\" -type f \\( -name \"*.keras\" -o -name \"*.h5\" \\) | sort || true\n",
        "\n",
        "echo\n",
        "echo \"=== CSVs (with sizes) ===\"\n",
        "find \"$BASE\" -maxdepth 5 -type f -iname \"*.csv\" -printf \"%p\\t%k KB\\n\" | sort || true\n",
        "\n",
        "echo\n",
        "echo \"=== Image folders (top 50 by file count) ===\"\n",
        "find \"$BASE\" -type f \\( -iname \"*.png\" -o -iname \"*.jpg\" -o -iname \"*.jpeg\" -o -iname \"*.bmp\" -o -iname \"*.tif\" -o -iname \"*.tiff\" -o -iname \"*.webp\" \\) \\\n",
        "| sed -r 's|/[^/]+$||' | sort | uniq -c | sort -nr | head -n 50 || true\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "s0k-zD7lcYht",
        "outputId": "1035ca7e-bb92-41fd-95e6-840b1336d682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.0).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/subhajeetdas/aptos-2019-jpg?dataset_version_number=12...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.82G/2.82G [00:33<00:00, 88.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Built test CSV from class-folders in kagglehub dataset:\n",
            "    root=/root/.cache/kagglehub/datasets/subhajeetdas/aptos-2019-jpg/versions/12/APTOS 2019 (Original) (Binary)\n",
            "    rows=3662\n",
            "    → /content/drive/MyDrive/DiabeticProject/test.csv\n",
            "Head of test.csv:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                            filepath label\n",
              "0  /root/.cache/kagglehub/datasets/subhajeetdas/a...    DR\n",
              "1  /root/.cache/kagglehub/datasets/subhajeetdas/a...    DR\n",
              "2  /root/.cache/kagglehub/datasets/subhajeetdas/a...    DR\n",
              "3  /root/.cache/kagglehub/datasets/subhajeetdas/a...    DR\n",
              "4  /root/.cache/kagglehub/datasets/subhajeetdas/a...    DR"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c00c658-3495-438e-abe7-3b9b0af59cd7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filepath</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/root/.cache/kagglehub/datasets/subhajeetdas/a...</td>\n",
              "      <td>DR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/root/.cache/kagglehub/datasets/subhajeetdas/a...</td>\n",
              "      <td>DR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/root/.cache/kagglehub/datasets/subhajeetdas/a...</td>\n",
              "      <td>DR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/root/.cache/kagglehub/datasets/subhajeetdas/a...</td>\n",
              "      <td>DR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/root/.cache/kagglehub/datasets/subhajeetdas/a...</td>\n",
              "      <td>DR</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c00c658-3495-438e-abe7-3b9b0af59cd7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0c00c658-3495-438e-abe7-3b9b0af59cd7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0c00c658-3495-438e-abe7-3b9b0af59cd7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Rows:\\\", len(df))\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"filepath\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/root/.cache/kagglehub/datasets/subhajeetdas/aptos-2019-jpg/versions/12/APTOS 2019 (Original) (Binary)/DR/image_00737.png\",\n          \"/root/.cache/kagglehub/datasets/subhajeetdas/aptos-2019-jpg/versions/12/APTOS 2019 (Original) (Binary)/DR/image_4 (23).png\",\n          \"/root/.cache/kagglehub/datasets/subhajeetdas/aptos-2019-jpg/versions/12/APTOS 2019 (Original) (Binary)/DR/image_01722.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"DR\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 3662\n"
          ]
        }
      ],
      "source": [
        "# Cell 2 — Build /content/drive/MyDrive/DiabeticProject/test.csv robustly\n",
        "import os, glob, pandas as pd, zipfile, io\n",
        "from google.colab import files as colab_files  # avoid name clash\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/DiabeticProject\"\n",
        "OUT_CSV = f\"{BASE}/test.csv\"\n",
        "os.makedirs(BASE, exist_ok=True)\n",
        "\n",
        "IMG_EXTS = (\".png\",\".jpg\",\".jpeg\",\".bmp\",\".tif\",\".tiff\",\".webp\")\n",
        "\n",
        "def valid_test_csv(path):\n",
        "    if not os.path.exists(path): return False\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        if not {\"filepath\",\"label\"}.issubset(df.columns): return False\n",
        "        df = df[df[\"filepath\"].apply(os.path.exists)]\n",
        "        return len(df) > 0\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def build_df_from_class_folder(root):\n",
        "    \"\"\"root should contain subfolders per class; we create filepath,label rows.\"\"\"\n",
        "    rows = []\n",
        "    if not os.path.isdir(root): return None\n",
        "    subdirs = [d for d in sorted(os.listdir(root)) if os.path.isdir(os.path.join(root, d))]\n",
        "    if not subdirs: return None\n",
        "    has_any = False\n",
        "    for cls in subdirs:\n",
        "        cls_path = os.path.join(root, cls)\n",
        "        files_in_cls = [f for f in os.listdir(cls_path) if os.path.isfile(os.path.join(cls_path, f))]\n",
        "        img_files = [f for f in files_in_cls if f.lower().endswith(IMG_EXTS)]\n",
        "        for f in img_files:\n",
        "            rows.append((os.path.join(cls_path, f), str(cls)))\n",
        "        if img_files:\n",
        "            has_any = True\n",
        "    if not has_any:\n",
        "        return None\n",
        "    df = pd.DataFrame(rows, columns=[\"filepath\",\"label\"])\n",
        "    df = df[df[\"filepath\"].apply(os.path.exists)].reset_index(drop=True)\n",
        "    return df if len(df) else None\n",
        "\n",
        "def find_class_folder_dataset(base_dir, max_depth=3):\n",
        "    \"\"\"\n",
        "    Heuristic: find a directory whose immediate subdirs contain images.\n",
        "    Searches a few common names first, then a shallow walk.\n",
        "    \"\"\"\n",
        "    candidates = []\n",
        "    common = [\"test_images\",\"val_images\",\"valid_images\",\"test\",\"val\",\"valid\",\"train_images\",\"train\",\"images/train\",\"dataset/train\"]\n",
        "    for name in common:\n",
        "        p = os.path.join(base_dir, name)\n",
        "        if os.path.isdir(p):\n",
        "            candidates.append(p)\n",
        "\n",
        "    # add shallow scan\n",
        "    for r, dirs, files in os.walk(base_dir):\n",
        "        depth = r[len(base_dir):].count(os.sep)\n",
        "        if depth > max_depth:\n",
        "            continue\n",
        "        for d in dirs:\n",
        "            candidates.append(os.path.join(r, d))\n",
        "\n",
        "    # check candidates\n",
        "    seen = set()\n",
        "    for c in candidates:\n",
        "        c = os.path.normpath(c)\n",
        "        if c in seen:\n",
        "            continue\n",
        "        seen.add(c)\n",
        "        df = build_df_from_class_folder(c)\n",
        "        if df is not None and len(df) >= 20:  # sanity threshold\n",
        "            return c, df\n",
        "    return None, None\n",
        "\n",
        "def try_build_from_aptos_anywhere():\n",
        "    \"\"\"Find any train.csv in Drive and build OUT_CSV (.png/.jpg/.jpeg supported).\"\"\"\n",
        "    cands = glob.glob(\"/content/drive/**/train.csv\", recursive=True)\n",
        "    for csv_path in cands:\n",
        "        try:\n",
        "            df = pd.read_csv(csv_path)\n",
        "            if not {\"id_code\",\"diagnosis\"}.issubset(df.columns):\n",
        "                continue\n",
        "            root = os.path.dirname(csv_path)\n",
        "            img_roots = [\n",
        "                os.path.join(root, \"train_images\"),\n",
        "                os.path.join(root, \"images\", \"train\"),\n",
        "                os.path.join(root, \"train\"),\n",
        "            ]\n",
        "            img_root = next((r for r in img_roots if os.path.isdir(r)), None)\n",
        "            if img_root is None:\n",
        "                continue\n",
        "\n",
        "            paths, labels = [], []\n",
        "            for _, row in df.iterrows():\n",
        "                idc = str(row[\"id_code\"])\n",
        "                for ext in [\".png\",\".jpg\",\".jpeg\"]:\n",
        "                    p = os.path.join(img_root, f\"{idc}{ext}\")\n",
        "                    if os.path.exists(p):\n",
        "                        paths.append(p); labels.append(int(row[\"diagnosis\"]))\n",
        "                        break\n",
        "            if not paths:\n",
        "                continue\n",
        "            pd.DataFrame({\"filepath\":paths,\"label\":labels}).to_csv(OUT_CSV, index=False)\n",
        "            print(f\"✅ Built test CSV from APTOS in Drive: {OUT_CSV}  ({len(paths)} rows)\")\n",
        "            return True\n",
        "        except Exception:\n",
        "            pass\n",
        "    return False\n",
        "\n",
        "def try_build_from_kagglehub_or_classfolders():\n",
        "    \"\"\"Use kagglehub if available; if no train.csv, still try class-folder scanning inside the dataset.\"\"\"\n",
        "    try:\n",
        "        import kagglehub\n",
        "        dpath = kagglehub.dataset_download('subhajeetdas/aptos-2019-jpg')\n",
        "        # First, if there is a train.csv, use it:\n",
        "        csvs = glob.glob(os.path.join(dpath, \"**\", \"train.csv\"), recursive=True)\n",
        "        if csvs:\n",
        "            csv_path = csvs[0]\n",
        "            df = pd.read_csv(csv_path)\n",
        "            if {\"id_code\",\"diagnosis\"}.issubset(df.columns):\n",
        "                # try to guess an images root near the csv\n",
        "                guess_roots = [\n",
        "                    os.path.join(os.path.dirname(csv_path), \"train_images\"),\n",
        "                    os.path.join(os.path.dirname(csv_path), \"train\"),\n",
        "                    os.path.dirname(csv_path),\n",
        "                    dpath,\n",
        "                ]\n",
        "                img_root = None\n",
        "                for r in guess_roots:\n",
        "                    if os.path.isdir(r):\n",
        "                        img_root = r; break\n",
        "                if img_root:\n",
        "                    paths, labels = [], []\n",
        "                    for _, row in df.iterrows():\n",
        "                        idc = str(row[\"id_code\"])\n",
        "                        for ext in [\".png\",\".jpg\",\".jpeg\"]:\n",
        "                            p = os.path.join(img_root, f\"{idc}{ext}\")\n",
        "                            if os.path.exists(p):\n",
        "                                paths.append(p); labels.append(int(row[\"diagnosis\"]))\n",
        "                                break\n",
        "                    if paths:\n",
        "                        pd.DataFrame({\"filepath\":paths,\"label\":labels}).to_csv(OUT_CSV, index=False)\n",
        "                        print(f\"✅ Built test CSV from kagglehub(train.csv): {OUT_CSV}  ({len(paths)} rows)\")\n",
        "                        return True\n",
        "        # No train.csv? Try class-folder layout inside kaggle dataset\n",
        "        root, df_cf = find_class_folder_dataset(dpath, max_depth=4)\n",
        "        if df_cf is not None:\n",
        "            df_cf.to_csv(OUT_CSV, index=False)\n",
        "            print(f\"✅ Built test CSV from class-folders in kagglehub dataset:\\n    root={root}\\n    rows={len(df_cf)}\\n    → {OUT_CSV}\")\n",
        "            return True\n",
        "        print(\"kagglehub dataset found but no train.csv or class-folder dataset detected.\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(\"kagglehub not available or failed:\", e)\n",
        "        return False\n",
        "\n",
        "def try_build_from_zip_upload():\n",
        "    \"\"\"\n",
        "    Prompt a ZIP upload with folders per class:\n",
        "      test_images/\n",
        "        0/*.png ...\n",
        "        1/*.png ...\n",
        "    \"\"\"\n",
        "    print(\"⚠️ Upload a ZIP with folders per class (e.g., test_images/0, test_images/1, ...).\")\n",
        "    uploaded = colab_files.upload()\n",
        "    if not uploaded:\n",
        "        return False\n",
        "    zip_name = list(uploaded.keys())[0]\n",
        "    extract_dir = \"/content/uploaded_images\"\n",
        "    os.makedirs(extract_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(io.BytesIO(uploaded[zip_name]), 'r') as zf:\n",
        "        zf.extractall(extract_dir)\n",
        "\n",
        "    # Build CSV from extracted structure\n",
        "    rows = []\n",
        "    for root, dirnames, filenames in os.walk(extract_dir):  # <- renamed to avoid shadowing\n",
        "        if root == extract_dir:\n",
        "            continue\n",
        "        label = os.path.basename(root)\n",
        "        for fn in filenames:\n",
        "            if fn.lower().endswith(IMG_EXTS):\n",
        "                rows.append((os.path.join(root, fn), label))\n",
        "    if not rows:\n",
        "        print(\"ZIP extracted but no images found.\")\n",
        "        return False\n",
        "    df = pd.DataFrame(rows, columns=[\"filepath\",\"label\"])\n",
        "    df.to_csv(OUT_CSV, index=False)\n",
        "    print(f\"✅ Built test CSV from uploaded ZIP: {OUT_CSV}  ({len(df)} rows)\")\n",
        "    return True\n",
        "\n",
        "# ---- main flow\n",
        "if valid_test_csv(OUT_CSV):\n",
        "    print(f\"✅ Using existing test CSV: {OUT_CSV}\")\n",
        "else:\n",
        "    if try_build_from_aptos_anywhere():\n",
        "        pass\n",
        "    elif try_build_from_kagglehub_or_classfolders():\n",
        "        pass\n",
        "    else:\n",
        "        print(\"Could not find APTOS in Drive or usable class-folders.\")\n",
        "        ok = try_build_from_zip_upload()\n",
        "        if not ok:\n",
        "            raise FileNotFoundError(\n",
        "                \"No usable test set. Re-run this cell and upload a ZIP with folders per class, \"\n",
        "                \"or place APTOS train.csv + train_images/ in Drive.\"\n",
        "            )\n",
        "\n",
        "# Preview\n",
        "df = pd.read_csv(OUT_CSV)\n",
        "print(\"Head of test.csv:\")\n",
        "display(df.head())\n",
        "print(\"Rows:\", len(df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh1KIaFvcg3V",
        "outputId": "23c6b6e7-09e4-44dc-aacd-4ca24d0fb0c9"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using /content/drive/MyDrive/DiabeticProject/test.csv (rows=3662)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
            "EfficientNetV2B0_model_fp16.tflite: 100%|██████████| 3662/3662 [1:09:17<00:00,  1.14s/it]\n",
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " {'model': 'EfficientNetV2B0_model_fp16.tflite', 'images': 3662, 'avg_inference_time_ms': 1032.7791, 'accuracy': np.float64(0.492627), 'sensitivity': 0.158858, 'specificity': 0.836011, 'FPR': 0.163989, 'FNR': 0.841142, 'tn': 1509, 'fp': 296, 'fn': 1562, 'tp': 295, 'input_dtype': \"<class 'numpy.float32'>\", 'input_shape': [1, 256, 256, 3], 'output_len': 2, 'tflite_size_mb': 12.94}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EfficientNetV2B0_model_fp32.tflite: 100%|██████████| 3662/3662 [1:09:07<00:00,  1.13s/it]\n",
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " {'model': 'EfficientNetV2B0_model_fp32.tflite', 'images': 3662, 'avg_inference_time_ms': 1029.4526, 'accuracy': np.float64(0.493446), 'sensitivity': 0.166397, 'specificity': 0.829917, 'FPR': 0.170083, 'FNR': 0.833603, 'tn': 1498, 'fp': 307, 'fn': 1548, 'tp': 309, 'input_dtype': \"<class 'numpy.float32'>\", 'input_shape': [1, 256, 256, 3], 'output_len': 2, 'tflite_size_mb': 25.74}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EfficientNetV2B0_model_int8.tflite: 100%|██████████| 3662/3662 [1:11:16<00:00,  1.17s/it]\n",
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " {'model': 'EfficientNetV2B0_model_int8.tflite', 'images': 3662, 'avg_inference_time_ms': 1066.3383, 'accuracy': np.float64(0.516931), 'sensitivity': 0.981152, 'specificity': 0.039335, 'FPR': 0.960665, 'FNR': 0.018848, 'tn': 71, 'fp': 1734, 'fn': 35, 'tp': 1822, 'input_dtype': \"<class 'numpy.uint8'>\", 'input_shape': [1, 256, 256, 3], 'output_len': 2, 'tflite_size_mb': 7.68}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "InceptionV3_model_fp16.tflite:  47%|████▋     | 1735/3662 [24:50<25:41,  1.25it/s]"
          ]
        }
      ],
      "source": [
        "# Quantized TFLite evaluator aligned with your parent code (binary DR vs No-DR)\n",
        "import os, time, glob, numpy as np, pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# ===== CONFIG =====\n",
        "# Your 9 models (updated paths)\n",
        "MODEL_PATHS = [\n",
        "    \"/content/drive/MyDrive/DiabeticProject/tflite/EfficientNetV2B0_model_fp16.tflite\",\n",
        "    \"/content/drive/MyDrive/DiabeticProject/tflite/EfficientNetV2B0_model_fp32.tflite\",\n",
        "    \"/content/drive/MyDrive/DiabeticProject/tflite/EfficientNetV2B0_model_int8.tflite\",\n",
        "    \"/content/drive/MyDrive/DiabeticProject/tflite/InceptionV3_model_fp16.tflite\",\n",
        "    \"/content/drive/MyDrive/DiabeticProject/tflite/InceptionV3_model_fp32.tflite\",\n",
        "    \"/content/drive/MyDrive/DiabeticProject/tflite/InceptionV3_model_int8.tflite\",\n",
        "   \"/content/drive/MyDrive/DiabeticProject/tflite/MobileNetV2_model_fp16.tflite\",\n",
        "    \"/content/drive/MyDrive/DiabeticProject/tflite/MobileNetV2_model_fp32.tflite\",\n",
        "    \"/content/drive/MyDrive/DiabeticProject/tflite/MobileNetV2_model_int8.tflite\",\n",
        "]\n",
        "SAVE_SUMMARY_CSV = \"/content/drive/MyDrive/DiabeticProject/tflite_eval_summary.csv\"\n",
        "\n",
        "# Which string in a CSV should count as \"DR\" if we end up reading strings:\n",
        "POSITIVE_LABEL_NAME = \"DR\"\n",
        "\n",
        "# APTOS 5-class convention for No-DR id:\n",
        "NO_DR_CLASS_ID_FOR_5CLASS = 0\n",
        "\n",
        "# For true binary softmax/order [NoDR, DR], which index is DR?\n",
        "DR_CLASS_INDEX_FOR_BINARY = 1\n",
        "\n",
        "# TFLite threads (optional)\n",
        "NUM_THREADS = 4\n",
        "\n",
        "# speed/controls\n",
        "WARMUP_RUNS = 5\n",
        "LIMIT_IMAGES = None # e.g., 500 for a quick pass; None = all\n",
        "# ===================\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def get_preprocess_from_name(model_path):\n",
        "    \"\"\"Choose the same preprocess used during training.\"\"\"\n",
        "    name = os.path.basename(model_path).lower()\n",
        "    # defaults to [0,1] scaling\n",
        "    f = lambda x: x / 255.0\n",
        "\n",
        "    if \"efficientnetv2\" in name or \"efficientnetv2b0\" in name:\n",
        "        f = tf.keras.applications.efficientnet_v2.preprocess_input\n",
        "    elif \"inceptionv3\" in name:\n",
        "        f = tf.keras.applications.inception_v3.preprocess_input\n",
        "    elif \"mobilenetv2\" in name:\n",
        "        f = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "    # keep a few extras in case you add them later\n",
        "    elif \"resnet50v2\" in name or \"resnetv2\" in name:\n",
        "        f = tf.keras.applications.resnet_v2.preprocess_input\n",
        "    elif \"nasnetmobile\" in name or \"nasnet\" in name:\n",
        "        f = tf.keras.applications.nasnet.preprocess_input\n",
        "    elif \"densenet121\" in name or \"densenet\" in name:\n",
        "        f = tf.keras.applications.densenet.preprocess_input\n",
        "\n",
        "    return f\n",
        "\n",
        "def quantize_np(x_float, scale, zero_point, dtype):\n",
        "    if scale is None or scale == 0:\n",
        "        return x_float.astype(dtype)\n",
        "    q = np.round(x_float / scale + zero_point)\n",
        "    if np.issubdtype(dtype, np.integer):\n",
        "        info = np.iinfo(dtype)\n",
        "        q = np.clip(q, info.min, info.max)\n",
        "    return q.astype(dtype)\n",
        "\n",
        "def dequantize_np(q, scale, zero_point):\n",
        "    if scale is None or scale == 0:\n",
        "        return q.astype(np.float32)\n",
        "    return scale * (q.astype(np.float32) - zero_point)\n",
        "\n",
        "def load_and_prep(path, target_hw, preprocess_fn):\n",
        "    # target_hw = (W, H)\n",
        "    img = Image.open(path).convert(\"RGB\").resize(target_hw, Image.BILINEAR)\n",
        "    x = np.array(img, dtype=np.float32)\n",
        "    x = preprocess_fn(x)\n",
        "    return np.expand_dims(x, 0)\n",
        "\n",
        "def file_mb(path):\n",
        "    try:\n",
        "        return round(os.path.getsize(path)/ (1024*1024), 2)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# ---------- load ground truth like your parent pipeline ----------\n",
        "def load_test_dataframe():\n",
        "    # 1) Use your in-memory test_df if present with columns (image_path, label)\n",
        "    g = globals()\n",
        "    if \"test_df\" in g and isinstance(g[\"test_df\"], pd.core.frame.DataFrame):\n",
        "        df = g[\"test_df\"].copy()\n",
        "        if {\"image_path\",\"label\"}.issubset(df.columns):\n",
        "            df = df.rename(columns={\"image_path\":\"filepath\"})\n",
        "            df[\"label\"] = df[\"label\"].astype(int)  # parent code uses 1 for DR, 0 for No DR\n",
        "            df[\"y_true\"] = df[\"label\"]\n",
        "            print(f\"Using in-memory test_df (rows={len(df)})\")\n",
        "            return df[[\"filepath\",\"y_true\"]].reset_index(drop=True)\n",
        "\n",
        "    # 2) Fallback to the test.csv we created earlier (DR/No DR strings or 0/1)\n",
        "    csv_path = \"/content/drive/MyDrive/DiabeticProject/test.csv\"\n",
        "    if os.path.exists(csv_path):\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if {\"filepath\",\"label\"}.issubset(df.columns):\n",
        "            # accept either \"DR\"/\"No DR\" strings or numeric 0/1\n",
        "            if df[\"label\"].dtype == object:\n",
        "                lab = df[\"label\"].astype(str).str.strip().str.lower()\n",
        "                df[\"y_true\"] = (lab == POSITIVE_LABEL_NAME.lower()).astype(int)\n",
        "            else:\n",
        "                df[\"y_true\"] = df[\"label\"].astype(int)\n",
        "            print(f\"Using {csv_path} (rows={len(df)})\")\n",
        "            return df[[\"filepath\",\"y_true\"]].reset_index(drop=True)\n",
        "\n",
        "    raise FileNotFoundError(\n",
        "        \"No test set found. Either keep your parent session variables alive (test_df with image_path,label), \"\n",
        "        \"or ensure /content/drive/MyDrive/DiabeticProject/test.csv exists with columns filepath,label.\"\n",
        "    )\n",
        "\n",
        "# ---------- core evaluation ----------\n",
        "def evaluate_tflite_binary(model_path, df):\n",
        "    interpreter = tf.lite.Interpreter(model_path=model_path, num_threads=NUM_THREADS)\n",
        "    interpreter.allocate_tensors()\n",
        "    in_det = interpreter.get_input_details()[0]\n",
        "    out_det = interpreter.get_output_details()[0]\n",
        "\n",
        "    _, H, W, C = in_det[\"shape\"]\n",
        "    in_dtype = in_det[\"dtype\"]\n",
        "    in_scale, in_zp = in_det.get(\"quantization\", (None, None))\n",
        "    out_dtype = out_det[\"dtype\"]\n",
        "    out_scale, out_zp = out_det.get(\"quantization\", (None, None))\n",
        "\n",
        "    preprocess_fn = get_preprocess_from_name(model_path)\n",
        "\n",
        "    N = len(df) if LIMIT_IMAGES is None else min(LIMIT_IMAGES, len(df))\n",
        "\n",
        "    # warmup\n",
        "    dummy = np.zeros((1, H, W, C), dtype=np.float32)\n",
        "    dummy = preprocess_fn(dummy)\n",
        "    dummy_q = quantize_np(dummy, in_scale, in_zp, in_dtype) if in_dtype != np.float32 else dummy.astype(in_dtype)\n",
        "    interpreter.set_tensor(in_det[\"index\"], dummy_q)\n",
        "    for _ in range(max(0, WARMUP_RUNS)):\n",
        "        interpreter.invoke(); _ = interpreter.get_tensor(out_det[\"index\"])\n",
        "\n",
        "    times = []\n",
        "    y_pred = []\n",
        "    out_len_first = None\n",
        "\n",
        "    for i in tqdm(range(N), desc=os.path.basename(model_path)):\n",
        "        fp = df.iloc[i][\"filepath\"]\n",
        "        x = load_and_prep(fp, (W, H), preprocess_fn)\n",
        "        x = quantize_np(x, in_scale, in_zp, in_dtype) if in_dtype != np.float32 else x.astype(in_dtype)\n",
        "\n",
        "        interpreter.set_tensor(in_det[\"index\"], x)\n",
        "        t0 = time.perf_counter(); interpreter.invoke(); t1 = time.perf_counter()\n",
        "        out = interpreter.get_tensor(out_det[\"index\"])\n",
        "        out = dequantize_np(out, out_scale, out_zp) if out_dtype != np.float32 else out\n",
        "        out = np.squeeze(out)\n",
        "\n",
        "        # Map model output -> binary prediction (DR=1, NoDR=0)\n",
        "        if out.ndim == 0:\n",
        "            prob = 1 / (1 + np.exp(-out))\n",
        "            pred_bin = int(prob >= 0.5)\n",
        "            out_len_first = out_len_first or 1\n",
        "        elif out.ndim == 1:\n",
        "            K = out.shape[0]; out_len_first = out_len_first or K\n",
        "            if K == 1:\n",
        "                prob = 1 / (1 + np.exp(-out[0])); pred_bin = int(prob >= 0.5)\n",
        "            elif K == 2:\n",
        "                pred_bin = int(np.argmax(out) == DR_CLASS_INDEX_FOR_BINARY)\n",
        "            else:\n",
        "                # 5-class APTOS: class 0 is No-DR -> DR if argmax != 0\n",
        "                pred_bin = int(np.argmax(out) != NO_DR_CLASS_ID_FOR_5CLASS)\n",
        "        else:\n",
        "            pred_bin = int(np.argmax(out) != NO_DR_CLASS_ID_FOR_5CLASS)\n",
        "\n",
        "        y_pred.append(pred_bin)\n",
        "        times.append((t1 - t0) * 1000.0)\n",
        "\n",
        "    y_true = df.iloc[:N][\"y_true\"].to_numpy(dtype=int)\n",
        "    y_pred = np.array(y_pred, dtype=int)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0,1]).ravel()\n",
        "    def safe(a,b): return float(a)/float(b) if b else 0.0\n",
        "    sensitivity = safe(tp, tp+fn)\n",
        "    specificity = safe(tn, tn+fp)\n",
        "    fpr = safe(fp, fp+tn)\n",
        "    fnr = safe(fn, fn+tp)\n",
        "    acc = (tp+tn) / (tp+tn+fp+fn)\n",
        "    avg_ms = float(np.mean(times))\n",
        "\n",
        "    return {\n",
        "        \"model\": os.path.basename(model_path),\n",
        "        \"images\": int(N),\n",
        "        \"avg_inference_time_ms\": round(avg_ms, 4),\n",
        "        \"accuracy\": round(acc, 6),\n",
        "        \"sensitivity\": round(sensitivity, 6),\n",
        "        \"specificity\": round(specificity, 6),\n",
        "        \"FPR\": round(fpr, 6),\n",
        "        \"FNR\": round(fnr, 6),\n",
        "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp),\n",
        "        \"input_dtype\": str(in_dtype),\n",
        "        \"input_shape\": [int(d) for d in in_det[\"shape\"]],\n",
        "        \"output_len\": out_len_first,\n",
        "        \"tflite_size_mb\": file_mb(model_path),\n",
        "    }\n",
        "\n",
        "# ---------- run ----------\n",
        "df_eval = load_test_dataframe()\n",
        "if LIMIT_IMAGES is not None:\n",
        "    df_eval = df_eval.sample(n=min(LIMIT_IMAGES, len(df_eval)), random_state=42).reset_index(drop=True)\n",
        "\n",
        "results = []\n",
        "for mp in [p for p in MODEL_PATHS if os.path.exists(p)]:\n",
        "    res = evaluate_tflite_binary(mp, df_eval)\n",
        "    results.append(res)\n",
        "    print(\"\\n\", res)\n",
        "\n",
        "cols = [\"model\",\"tflite_size_mb\",\"images\",\"avg_inference_time_ms\",\n",
        "        \"accuracy\",\"sensitivity\",\"specificity\",\"FPR\",\"FNR\",\n",
        "        \"tn\",\"fp\",\"fn\",\"tp\",\"input_dtype\",\"input_shape\",\"output_len\"]\n",
        "pd.DataFrame(results)[cols].to_csv(SAVE_SUMMARY_CSV, index=False)\n",
        "print(f\"\\nSaved summary → {SAVE_SUMMARY_CSV}\")\n",
        "pd.DataFrame(results)[cols]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNERzc-R3n8Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPVG1WLKeB0B8WHz+JxFojP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}