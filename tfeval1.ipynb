{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manushi0304/Diabetic_Retinopathy/blob/main/tfeval1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZz39U4kxAJG",
        "outputId": "0998236e-336b-4ea2-c8ae-e8ac9ea06afe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Using BASE = /content/drive/MyDrive/DiabeticProject\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/DiabeticProject\"\n",
        "print(\"Using BASE =\", BASE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SY_PyMTxH1N",
        "outputId": "5ef861c3-df0e-41d9-841f-67aaace5eb1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BASE: /content/drive/MyDrive/DiabeticProject\n",
            "=== TFLite models (.tflite) ===\n",
            "/content/drive/MyDrive/DiabeticProject/tflite/DenseNet121_model_fp16.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/tflite/DenseNet121_model_fp32.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/tflite/DenseNet121_model_int8.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/tflite/NASNetMobile_model_fp16.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/tflite/NASNetMobile_model_fp32.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/tflite/NASNetMobile_model_int8.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/tflite/ResNet50V2model_fp16.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/tflite/ResNet50V2model_fp32.tflite\n",
            "/content/drive/MyDrive/DiabeticProject/tflite/ResNet50V2model_int8.tflite\n",
            "\n",
            "=== Parent models (.keras / .h5) ===\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/DenseNet121_single/latest_model.keras\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/DenseNet121_single_split.keras\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/NASNetMobile_single/latest_model.keras\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/NASNetMobile_single_split.keras\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/ResNet50V2_single/latest_model.keras\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/ResNet50V2_single_split.keras\n",
            "\n",
            "=== CSVs (with sizes) ===\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/DenseNet121_single/training_log.csv\t7 KB\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/EfficientNetV2B0_single/training_log.csv\t0 KB\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/NASNetMobile_single/training_log.csv\t7 KB\n",
            "/content/drive/MyDrive/DiabeticProject/saved_models/ResNet50V2_single/training_log.csv\t7 KB\n",
            "/content/drive/MyDrive/DiabeticProject/test.csv\t459 KB\n",
            "/content/drive/MyDrive/DiabeticProject/training_logs/all_models_training_log.csv\t3 KB\n",
            "/content/drive/MyDrive/DiabeticProject/training_logs/DenseNet121_training_log.csv\t4 KB\n",
            "/content/drive/MyDrive/DiabeticProject/training_logs/EfficientNetV2B0_training_log.csv\t1 KB\n",
            "/content/drive/MyDrive/DiabeticProject/training_logs/final_test_results.csv\t2 KB\n",
            "/content/drive/MyDrive/DiabeticProject/training_logs/NASNetMobile_training_log.csv\t3 KB\n",
            "/content/drive/MyDrive/DiabeticProject/training_logs/ResNet50V2_training_log.csv\t2 KB\n",
            "\n",
            "=== Image folders (top 50 by file count) ===\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "BASE=\"/content/drive/MyDrive/DiabeticProject\"\n",
        "\n",
        "echo \"BASE: $BASE\"\n",
        "\n",
        "echo \"=== TFLite models (.tflite) ===\"\n",
        "find \"$BASE\" -type f -name \"*.tflite\" | sort || true\n",
        "\n",
        "echo\n",
        "echo \"=== Parent models (.keras / .h5) ===\"\n",
        "find \"$BASE\" -type f \\( -name \"*.keras\" -o -name \"*.h5\" \\) | sort || true\n",
        "\n",
        "echo\n",
        "echo \"=== CSVs (with sizes) ===\"\n",
        "find \"$BASE\" -maxdepth 5 -type f -iname \"*.csv\" -printf \"%p\\t%k KB\\n\" | sort || true\n",
        "\n",
        "echo\n",
        "echo \"=== Image folders (top 50 by file count) ===\"\n",
        "find \"$BASE\" -type f \\( -iname \"*.png\" -o -iname \"*.jpg\" -o -iname \"*.jpeg\" -o -iname \"*.bmp\" -o -iname \"*.tif\" -o -iname \"*.tiff\" -o -iname \"*.webp\" \\) \\\n",
        "| sed -r 's|/[^/]+$||' | sort | uniq -c | sort -nr | head -n 50 || true\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "Ijs6cs4xx8rm",
        "outputId": "d1e1ce8c-3204-4478-ea90-3783af64a08a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/subhajeetdas/aptos-2019-jpg?dataset_version_number=12...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2.82G/2.82G [00:34<00:00, 87.9MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Built test CSV from class-folders in kagglehub dataset:\n",
            "    root=/root/.cache/kagglehub/datasets/subhajeetdas/aptos-2019-jpg/versions/12/APTOS 2019 (Original) (Binary)\n",
            "    rows=3662\n",
            "    → /content/drive/MyDrive/DiabeticProject/test.csv\n",
            "Head of test.csv:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"print(\\\"Rows:\\\", len(df))\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"filepath\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/root/.cache/kagglehub/datasets/subhajeetdas/aptos-2019-jpg/versions/12/APTOS 2019 (Original) (Binary)/DR/image_00176.png\",\n          \"/root/.cache/kagglehub/datasets/subhajeetdas/aptos-2019-jpg/versions/12/APTOS 2019 (Original) (Binary)/DR/image_00123.png\",\n          \"/root/.cache/kagglehub/datasets/subhajeetdas/aptos-2019-jpg/versions/12/APTOS 2019 (Original) (Binary)/DR/image_00215.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"DR\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-aafce670-eb9c-4662-ba71-5b2517849ec2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filepath</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/root/.cache/kagglehub/datasets/subhajeetdas/a...</td>\n",
              "      <td>DR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/root/.cache/kagglehub/datasets/subhajeetdas/a...</td>\n",
              "      <td>DR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/root/.cache/kagglehub/datasets/subhajeetdas/a...</td>\n",
              "      <td>DR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/root/.cache/kagglehub/datasets/subhajeetdas/a...</td>\n",
              "      <td>DR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/root/.cache/kagglehub/datasets/subhajeetdas/a...</td>\n",
              "      <td>DR</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aafce670-eb9c-4662-ba71-5b2517849ec2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aafce670-eb9c-4662-ba71-5b2517849ec2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aafce670-eb9c-4662-ba71-5b2517849ec2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f1ab4ef6-6728-4def-ad0a-12784de9f143\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f1ab4ef6-6728-4def-ad0a-12784de9f143')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f1ab4ef6-6728-4def-ad0a-12784de9f143 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            filepath label\n",
              "0  /root/.cache/kagglehub/datasets/subhajeetdas/a...    DR\n",
              "1  /root/.cache/kagglehub/datasets/subhajeetdas/a...    DR\n",
              "2  /root/.cache/kagglehub/datasets/subhajeetdas/a...    DR\n",
              "3  /root/.cache/kagglehub/datasets/subhajeetdas/a...    DR\n",
              "4  /root/.cache/kagglehub/datasets/subhajeetdas/a...    DR"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows: 3662\n"
          ]
        }
      ],
      "source": [
        "# Cell 2 — Build /content/drive/MyDrive/DiabeticProject/test.csv robustly\n",
        "import os, glob, pandas as pd, zipfile, io\n",
        "from google.colab import files as colab_files  # avoid name clash\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/DiabeticProject\"\n",
        "OUT_CSV = f\"{BASE}/test.csv\"\n",
        "os.makedirs(BASE, exist_ok=True)\n",
        "\n",
        "IMG_EXTS = (\".png\",\".jpg\",\".jpeg\",\".bmp\",\".tif\",\".tiff\",\".webp\")\n",
        "\n",
        "def valid_test_csv(path):\n",
        "    if not os.path.exists(path): return False\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        if not {\"filepath\",\"label\"}.issubset(df.columns): return False\n",
        "        df = df[df[\"filepath\"].apply(os.path.exists)]\n",
        "        return len(df) > 0\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def build_df_from_class_folder(root):\n",
        "    \"\"\"root should contain subfolders per class; we create filepath,label rows.\"\"\"\n",
        "    rows = []\n",
        "    if not os.path.isdir(root): return None\n",
        "    subdirs = [d for d in sorted(os.listdir(root)) if os.path.isdir(os.path.join(root, d))]\n",
        "    if not subdirs: return None\n",
        "    has_any = False\n",
        "    for cls in subdirs:\n",
        "        cls_path = os.path.join(root, cls)\n",
        "        files_in_cls = [f for f in os.listdir(cls_path) if os.path.isfile(os.path.join(cls_path, f))]\n",
        "        img_files = [f for f in files_in_cls if f.lower().endswith(IMG_EXTS)]\n",
        "        for f in img_files:\n",
        "            rows.append((os.path.join(cls_path, f), str(cls)))\n",
        "        if img_files:\n",
        "            has_any = True\n",
        "    if not has_any:\n",
        "        return None\n",
        "    df = pd.DataFrame(rows, columns=[\"filepath\",\"label\"])\n",
        "    df = df[df[\"filepath\"].apply(os.path.exists)].reset_index(drop=True)\n",
        "    return df if len(df) else None\n",
        "\n",
        "def find_class_folder_dataset(base_dir, max_depth=3):\n",
        "    \"\"\"\n",
        "    Heuristic: find a directory whose immediate subdirs contain images.\n",
        "    Searches a few common names first, then a shallow walk.\n",
        "    \"\"\"\n",
        "    candidates = []\n",
        "    common = [\"test_images\",\"val_images\",\"valid_images\",\"test\",\"val\",\"valid\",\"train_images\",\"train\",\"images/train\",\"dataset/train\"]\n",
        "    for name in common:\n",
        "        p = os.path.join(base_dir, name)\n",
        "        if os.path.isdir(p):\n",
        "            candidates.append(p)\n",
        "\n",
        "    # add shallow scan\n",
        "    for r, dirs, files in os.walk(base_dir):\n",
        "        depth = r[len(base_dir):].count(os.sep)\n",
        "        if depth > max_depth:\n",
        "            continue\n",
        "        for d in dirs:\n",
        "            candidates.append(os.path.join(r, d))\n",
        "\n",
        "    # check candidates\n",
        "    seen = set()\n",
        "    for c in candidates:\n",
        "        c = os.path.normpath(c)\n",
        "        if c in seen:\n",
        "            continue\n",
        "        seen.add(c)\n",
        "        df = build_df_from_class_folder(c)\n",
        "        if df is not None and len(df) >= 20:  # sanity threshold\n",
        "            return c, df\n",
        "    return None, None\n",
        "\n",
        "def try_build_from_aptos_anywhere():\n",
        "    \"\"\"Find any train.csv in Drive and build OUT_CSV (.png/.jpg/.jpeg supported).\"\"\"\n",
        "    cands = glob.glob(\"/content/drive/**/train.csv\", recursive=True)\n",
        "    for csv_path in cands:\n",
        "        try:\n",
        "            df = pd.read_csv(csv_path)\n",
        "            if not {\"id_code\",\"diagnosis\"}.issubset(df.columns):\n",
        "                continue\n",
        "            root = os.path.dirname(csv_path)\n",
        "            img_roots = [\n",
        "                os.path.join(root, \"train_images\"),\n",
        "                os.path.join(root, \"images\", \"train\"),\n",
        "                os.path.join(root, \"train\"),\n",
        "            ]\n",
        "            img_root = next((r for r in img_roots if os.path.isdir(r)), None)\n",
        "            if img_root is None:\n",
        "                continue\n",
        "\n",
        "            paths, labels = [], []\n",
        "            for _, row in df.iterrows():\n",
        "                idc = str(row[\"id_code\"])\n",
        "                for ext in [\".png\",\".jpg\",\".jpeg\"]:\n",
        "                    p = os.path.join(img_root, f\"{idc}{ext}\")\n",
        "                    if os.path.exists(p):\n",
        "                        paths.append(p); labels.append(int(row[\"diagnosis\"]))\n",
        "                        break\n",
        "            if not paths:\n",
        "                continue\n",
        "            pd.DataFrame({\"filepath\":paths,\"label\":labels}).to_csv(OUT_CSV, index=False)\n",
        "            print(f\"✅ Built test CSV from APTOS in Drive: {OUT_CSV}  ({len(paths)} rows)\")\n",
        "            return True\n",
        "        except Exception:\n",
        "            pass\n",
        "    return False\n",
        "\n",
        "def try_build_from_kagglehub_or_classfolders():\n",
        "    \"\"\"Use kagglehub if available; if no train.csv, still try class-folder scanning inside the dataset.\"\"\"\n",
        "    try:\n",
        "        import kagglehub\n",
        "        dpath = kagglehub.dataset_download('subhajeetdas/aptos-2019-jpg')\n",
        "        # First, if there is a train.csv, use it:\n",
        "        csvs = glob.glob(os.path.join(dpath, \"**\", \"train.csv\"), recursive=True)\n",
        "        if csvs:\n",
        "            csv_path = csvs[0]\n",
        "            df = pd.read_csv(csv_path)\n",
        "            if {\"id_code\",\"diagnosis\"}.issubset(df.columns):\n",
        "                # try to guess an images root near the csv\n",
        "                guess_roots = [\n",
        "                    os.path.join(os.path.dirname(csv_path), \"train_images\"),\n",
        "                    os.path.join(os.path.dirname(csv_path), \"train\"),\n",
        "                    os.path.dirname(csv_path),\n",
        "                    dpath,\n",
        "                ]\n",
        "                img_root = None\n",
        "                for r in guess_roots:\n",
        "                    if os.path.isdir(r):\n",
        "                        img_root = r; break\n",
        "                if img_root:\n",
        "                    paths, labels = [], []\n",
        "                    for _, row in df.iterrows():\n",
        "                        idc = str(row[\"id_code\"])\n",
        "                        for ext in [\".png\",\".jpg\",\".jpeg\"]:\n",
        "                            p = os.path.join(img_root, f\"{idc}{ext}\")\n",
        "                            if os.path.exists(p):\n",
        "                                paths.append(p); labels.append(int(row[\"diagnosis\"]))\n",
        "                                break\n",
        "                    if paths:\n",
        "                        pd.DataFrame({\"filepath\":paths,\"label\":labels}).to_csv(OUT_CSV, index=False)\n",
        "                        print(f\"✅ Built test CSV from kagglehub(train.csv): {OUT_CSV}  ({len(paths)} rows)\")\n",
        "                        return True\n",
        "        # No train.csv? Try class-folder layout inside kaggle dataset\n",
        "        root, df_cf = find_class_folder_dataset(dpath, max_depth=4)\n",
        "        if df_cf is not None:\n",
        "            df_cf.to_csv(OUT_CSV, index=False)\n",
        "            print(f\"✅ Built test CSV from class-folders in kagglehub dataset:\\n    root={root}\\n    rows={len(df_cf)}\\n    → {OUT_CSV}\")\n",
        "            return True\n",
        "        print(\"kagglehub dataset found but no train.csv or class-folder dataset detected.\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(\"kagglehub not available or failed:\", e)\n",
        "        return False\n",
        "\n",
        "def try_build_from_zip_upload():\n",
        "    \"\"\"\n",
        "    Prompt a ZIP upload with folders per class:\n",
        "      test_images/\n",
        "        0/*.png ...\n",
        "        1/*.png ...\n",
        "    \"\"\"\n",
        "    print(\"⚠️ Upload a ZIP with folders per class (e.g., test_images/0, test_images/1, ...).\")\n",
        "    uploaded = colab_files.upload()\n",
        "    if not uploaded:\n",
        "        return False\n",
        "    zip_name = list(uploaded.keys())[0]\n",
        "    extract_dir = \"/content/uploaded_images\"\n",
        "    os.makedirs(extract_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(io.BytesIO(uploaded[zip_name]), 'r') as zf:\n",
        "        zf.extractall(extract_dir)\n",
        "\n",
        "    # Build CSV from extracted structure\n",
        "    rows = []\n",
        "    for root, dirnames, filenames in os.walk(extract_dir):  # <- renamed to avoid shadowing\n",
        "        if root == extract_dir:\n",
        "            continue\n",
        "        label = os.path.basename(root)\n",
        "        for fn in filenames:\n",
        "            if fn.lower().endswith(IMG_EXTS):\n",
        "                rows.append((os.path.join(root, fn), label))\n",
        "    if not rows:\n",
        "        print(\"ZIP extracted but no images found.\")\n",
        "        return False\n",
        "    df = pd.DataFrame(rows, columns=[\"filepath\",\"label\"])\n",
        "    df.to_csv(OUT_CSV, index=False)\n",
        "    print(f\"✅ Built test CSV from uploaded ZIP: {OUT_CSV}  ({len(df)} rows)\")\n",
        "    return True\n",
        "\n",
        "# ---- main flow\n",
        "if valid_test_csv(OUT_CSV):\n",
        "    print(f\"✅ Using existing test CSV: {OUT_CSV}\")\n",
        "else:\n",
        "    if try_build_from_aptos_anywhere():\n",
        "        pass\n",
        "    elif try_build_from_kagglehub_or_classfolders():\n",
        "        pass\n",
        "    else:\n",
        "        print(\"Could not find APTOS in Drive or usable class-folders.\")\n",
        "        ok = try_build_from_zip_upload()\n",
        "        if not ok:\n",
        "            raise FileNotFoundError(\n",
        "                \"No usable test set. Re-run this cell and upload a ZIP with folders per class, \"\n",
        "                \"or place APTOS train.csv + train_images/ in Drive.\"\n",
        "            )\n",
        "\n",
        "# Preview\n",
        "df = pd.read_csv(OUT_CSV)\n",
        "print(\"Head of test.csv:\")\n",
        "display(df.head())\n",
        "print(\"Rows:\", len(df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9I1pei3Xz0JE",
        "outputId": "9b8ed377-81b5-48ea-96da-78d28adf93ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using /content/drive/MyDrive/DiabeticProject/test.csv (rows=3662)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
            "DenseNet121_model_fp16.tflite: 100%|██████████| 3662/3662 [13:03<00:00,  4.67it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " {'model': 'DenseNet121_model_fp16.tflite', 'images': 3662, 'avg_inference_time_ms': 153.8063, 'accuracy': np.float64(0.594211), 'sensitivity': 0.304793, 'specificity': 0.891967, 'FPR': 0.108033, 'FNR': 0.695207, 'tn': 1610, 'fp': 195, 'fn': 1291, 'tp': 566, 'input_dtype': \"<class 'numpy.float32'>\", 'input_shape': [1, 256, 256, 3], 'output_len': 2, 'tflite_size_mb': 14.85}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DenseNet121_model_fp32.tflite:  41%|████      | 1498/3662 [05:19<07:41,  4.69it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-747104341.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODEL_PATHS\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_tflite_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-747104341.py\u001b[0m in \u001b[0;36mevaluate_tflite_binary\u001b[0;34m(model_path, df)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_det\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_det\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdequantize_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_zp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mout_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \"\"\"\n\u001b[1;32m    984\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Quantized TFLite evaluator aligned with your parent code (binary DR vs No-DR)\n",
        "import os, time, glob, numpy as np, pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# ===== CONFIG =====\n",
        "# Your 9 models (from your listing)\n",
        "MODEL_PATHS = [\n",
        "    \"/content/drive/MyDrive/DiabeticProject/tflite/DenseNet121_model_fp16.tflite\",\n",
        "    \"/content/drive/MyDrive/DiabeticProject/tflite/DenseNet121_model_fp32.tflite\",\n",
        "    \"/content/drive/MyDrive/DiabeticProject/tflite/DenseNet121_model_int8.tflite\",\n",
        "    \"/content/drive/MyDrive/DiabeticProject/tflite/NASNetMobile_model_fp16.tflite\",\n",
        "    \"/content/drive/MyDrive/DiabeticProject/tflite/NASNetMobile_model_fp32.tflite\",\n",
        "    \"/content/drive/MyDrive/DiabeticProject/tflite/NASNetMobile_model_int8.tflite\",\n",
        "    \"/content/drive/MyDrive/DiabeticProject/tflite/ResNet50V2model_fp16.tflite\",\n",
        "    \"/content/drive/MyDrive/DiabeticProject/tflite/ResNet50V2model_fp32.tflite\",\n",
        "    \"/content/drive/MyDrive/DiabeticProject/tflite/ResNet50V2model_int8.tflite\",\n",
        "]\n",
        "SAVE_SUMMARY_CSV = \"/content/drive/MyDrive/DiabeticProject/tflite_eval_summary.csv\"\n",
        "\n",
        "# Which string in a CSV should count as \"DR\" if we end up reading strings:\n",
        "POSITIVE_LABEL_NAME = \"DR\"\n",
        "\n",
        "# APTOS 5-class convention for No-DR id:\n",
        "NO_DR_CLASS_ID_FOR_5CLASS = 0\n",
        "\n",
        "# For true binary softmax/order [NoDR, DR], which index is DR?\n",
        "DR_CLASS_INDEX_FOR_BINARY = 1\n",
        "\n",
        "# speed/controls\n",
        "WARMUP_RUNS = 5\n",
        "LIMIT_IMAGES = None  # e.g., 500 for a quick pass; None = all\n",
        "# ===================\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def get_preprocess_from_name(model_path):\n",
        "    name = os.path.basename(model_path).lower()\n",
        "    f = lambda x: x / 255.0\n",
        "    if \"resnet50v2\" in name or \"resnetv2\" in name:\n",
        "        f = tf.keras.applications.resnet_v2.preprocess_input\n",
        "    elif \"nasnetmobile\" in name or \"nasnet\" in name:\n",
        "        f = tf.keras.applications.nasnet.preprocess_input\n",
        "    elif \"densenet121\" in name or \"densenet\" in name:\n",
        "        f = tf.keras.applications.densenet.preprocess_input\n",
        "    return f\n",
        "\n",
        "def quantize_np(x_float, scale, zero_point, dtype):\n",
        "    if scale is None or scale == 0: return x_float.astype(dtype)\n",
        "    q = np.round(x_float / scale + zero_point)\n",
        "    if np.issubdtype(dtype, np.integer):\n",
        "        info = np.iinfo(dtype); q = np.clip(q, info.min, info.max)\n",
        "    return q.astype(dtype)\n",
        "\n",
        "def dequantize_np(q, scale, zero_point):\n",
        "    if scale is None or scale == 0: return q.astype(np.float32)\n",
        "    return scale * (q.astype(np.float32) - zero_point)\n",
        "\n",
        "def load_and_prep(path, target_hw, preprocess_fn):\n",
        "    img = Image.open(path).convert(\"RGB\").resize(target_hw, Image.BILINEAR)\n",
        "    x = np.array(img, dtype=np.float32)\n",
        "    x = preprocess_fn(x)\n",
        "    return np.expand_dims(x, 0)\n",
        "\n",
        "def file_mb(path):\n",
        "    try:\n",
        "        return round(os.path.getsize(path)/ (1024*1024), 2)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# ---------- load ground truth like your parent pipeline ----------\n",
        "def load_test_dataframe():\n",
        "    # 1) Use your in-memory test_df if present with columns (image_path, label)\n",
        "    g = globals()\n",
        "    if \"test_df\" in g and isinstance(g[\"test_df\"], pd.core.frame.DataFrame):\n",
        "        df = g[\"test_df\"].copy()\n",
        "        if {\"image_path\",\"label\"}.issubset(df.columns):\n",
        "            df = df.rename(columns={\"image_path\":\"filepath\"})\n",
        "            # parent code uses 1 for DR, 0 for No DR\n",
        "            df[\"label\"] = df[\"label\"].astype(int)\n",
        "            df[\"y_true\"] = df[\"label\"]\n",
        "            print(f\"Using in-memory test_df (rows={len(df)})\")\n",
        "            return df[[\"filepath\",\"y_true\"]].reset_index(drop=True)\n",
        "\n",
        "    # 2) Fallback to the test.csv we created earlier (DR/No DR strings)\n",
        "    csv_path = \"/content/drive/MyDrive/DiabeticProject/test.csv\"\n",
        "    if os.path.exists(csv_path):\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if {\"filepath\",\"label\"}.issubset(df.columns):\n",
        "            lab = df[\"label\"].astype(str).str.strip().str.lower()\n",
        "            df[\"y_true\"] = (lab == POSITIVE_LABEL_NAME.lower()).astype(int)\n",
        "            print(f\"Using {csv_path} (rows={len(df)})\")\n",
        "            return df[[\"filepath\",\"y_true\"]].reset_index(drop=True)\n",
        "\n",
        "    raise FileNotFoundError(\n",
        "        \"No test set found. Either keep your parent session variables alive (test_df with image_path,label), \"\n",
        "        \"or ensure /content/drive/MyDrive/DiabeticProject/test.csv exists with columns filepath,label.\"\n",
        "    )\n",
        "\n",
        "# ---------- core evaluation ----------\n",
        "def evaluate_tflite_binary(model_path, df):\n",
        "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "    interpreter.allocate_tensors()\n",
        "    in_det = interpreter.get_input_details()[0]\n",
        "    out_det = interpreter.get_output_details()[0]\n",
        "\n",
        "    _, H, W, C = in_det[\"shape\"]\n",
        "    in_dtype = in_det[\"dtype\"]\n",
        "    in_scale, in_zp = in_det.get(\"quantization\", (None, None))\n",
        "    out_dtype = out_det[\"dtype\"]\n",
        "    out_scale, out_zp = out_det.get(\"quantization\", (None, None))\n",
        "\n",
        "    preprocess_fn = get_preprocess_from_name(model_path)\n",
        "\n",
        "    N = len(df) if LIMIT_IMAGES is None else min(LIMIT_IMAGES, len(df))\n",
        "\n",
        "    # warmup\n",
        "    dummy = np.zeros((1, H, W, C), dtype=np.float32)\n",
        "    dummy = preprocess_fn(dummy)\n",
        "    dummy_q = quantize_np(dummy, in_scale, in_zp, in_dtype) if in_dtype != np.float32 else dummy.astype(in_dtype)\n",
        "    interpreter.set_tensor(in_det[\"index\"], dummy_q)\n",
        "    for _ in range(max(0, WARMUP_RUNS)):\n",
        "        interpreter.invoke(); _ = interpreter.get_tensor(out_det[\"index\"])\n",
        "\n",
        "    times = []\n",
        "    y_pred = []\n",
        "    out_len_first = None\n",
        "\n",
        "    for i in tqdm(range(N), desc=os.path.basename(model_path)):\n",
        "        fp = df.iloc[i][\"filepath\"]\n",
        "        x = load_and_prep(fp, (W, H), preprocess_fn)\n",
        "        x = quantize_np(x, in_scale, in_zp, in_dtype) if in_dtype != np.float32 else x.astype(in_dtype)\n",
        "\n",
        "        interpreter.set_tensor(in_det[\"index\"], x)\n",
        "        t0 = time.perf_counter(); interpreter.invoke(); t1 = time.perf_counter()\n",
        "        out = interpreter.get_tensor(out_det[\"index\"])\n",
        "        out = dequantize_np(out, out_scale, out_zp) if out_dtype != np.float32 else out\n",
        "        out = np.squeeze(out)\n",
        "\n",
        "        # Map model output -> binary prediction (DR=1, NoDR=0)\n",
        "        if out.ndim == 0:\n",
        "            prob = 1 / (1 + np.exp(-out))\n",
        "            pred_bin = int(prob >= 0.5)\n",
        "            out_len_first = out_len_first or 1\n",
        "        elif out.ndim == 1:\n",
        "            K = out.shape[0]; out_len_first = out_len_first or K\n",
        "            if K == 1:\n",
        "                prob = 1 / (1 + np.exp(-out[0])); pred_bin = int(prob >= 0.5)\n",
        "            elif K == 2:\n",
        "                pred_bin = int(np.argmax(out) == DR_CLASS_INDEX_FOR_BINARY)\n",
        "            else:\n",
        "                # 5-class APTOS: class 0 is No-DR -> DR if argmax != 0\n",
        "                pred_bin = int(np.argmax(out) != NO_DR_CLASS_ID_FOR_5CLASS)\n",
        "        else:\n",
        "            pred_bin = int(np.argmax(out) != NO_DR_CLASS_ID_FOR_5CLASS)\n",
        "\n",
        "        y_pred.append(pred_bin)\n",
        "        times.append((t1 - t0) * 1000.0)\n",
        "\n",
        "    y_true = df.iloc[:N][\"y_true\"].to_numpy(dtype=int)\n",
        "    y_pred = np.array(y_pred, dtype=int)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0,1]).ravel()\n",
        "    def safe(a,b): return float(a)/float(b) if b else 0.0\n",
        "    sensitivity = safe(tp, tp+fn)\n",
        "    specificity = safe(tn, tn+fp)\n",
        "    fpr = safe(fp, fp+tn)\n",
        "    fnr = safe(fn, fn+tp)\n",
        "    acc = (tp+tn) / (tp+tn+fp+fn)\n",
        "    avg_ms = float(np.mean(times))\n",
        "\n",
        "    return {\n",
        "        \"model\": os.path.basename(model_path),\n",
        "        \"images\": int(N),\n",
        "        \"avg_inference_time_ms\": round(avg_ms, 4),\n",
        "        \"accuracy\": round(acc, 6),\n",
        "        \"sensitivity\": round(sensitivity, 6),\n",
        "        \"specificity\": round(specificity, 6),\n",
        "        \"FPR\": round(fpr, 6),\n",
        "        \"FNR\": round(fnr, 6),\n",
        "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp),\n",
        "        \"input_dtype\": str(in_dtype),\n",
        "        \"input_shape\": [int(d) for d in in_det[\"shape\"]],\n",
        "        \"output_len\": out_len_first,\n",
        "        \"tflite_size_mb\": file_mb(model_path),\n",
        "    }\n",
        "\n",
        "# ---------- run ----------\n",
        "df_eval = load_test_dataframe()\n",
        "if LIMIT_IMAGES is not None:\n",
        "    df_eval = df_eval.sample(n=min(LIMIT_IMAGES, len(df_eval)), random_state=42).reset_index(drop=True)\n",
        "\n",
        "results = []\n",
        "for mp in [p for p in MODEL_PATHS if os.path.exists(p)]:\n",
        "    res = evaluate_tflite_binary(mp, df_eval)\n",
        "    results.append(res)\n",
        "    print(\"\\n\", res)\n",
        "\n",
        "cols = [\"model\",\"tflite_size_mb\",\"images\",\"avg_inference_time_ms\",\n",
        "        \"accuracy\",\"sensitivity\",\"specificity\",\"FPR\",\"FNR\",\n",
        "        \"tn\",\"fp\",\"fn\",\"tp\",\"input_dtype\",\"input_shape\",\"output_len\"]\n",
        "pd.DataFrame(results)[cols].to_csv(SAVE_SUMMARY_CSV, index=False)\n",
        "print(f\"\\nSaved summary → {SAVE_SUMMARY_CSV}\")\n",
        "pd.DataFrame(results)[cols]\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}