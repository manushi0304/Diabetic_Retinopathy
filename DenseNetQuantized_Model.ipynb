{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manushi0304/Diabetic_Retinopathy/blob/main/DenseNetQuantized_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TufPuuAdn9pp",
        "outputId": "7c18842a-9f90-4a32-ad62-d414573d8874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/subhajeetdas/aptos-2019-jpg?dataset_version_number=12...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.82G/2.82G [00:26<00:00, 115MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images to evaluate:\n",
            " - /root/.cache/kagglehub/datasets/subhajeetdas/aptos-2019-jpg/versions/12/APTOS 2019 (Original) (Binary)/DR/image_00630.png\n",
            " - /root/.cache/kagglehub/datasets/subhajeetdas/aptos-2019-jpg/versions/12/APTOS 2019 (Original) (Binary)/No DR/image_01569.png\n",
            " - /root/.cache/kagglehub/datasets/subhajeetdas/aptos-2019-jpg/versions/12/APTOS 2019 (Original) (Binary)/DR/image_00655.png\n",
            " - /root/.cache/kagglehub/datasets/subhajeetdas/aptos-2019-jpg/versions/12/APTOS 2019 (Original) (Binary)/No DR/image_00712.png\n",
            " - /root/.cache/kagglehub/datasets/subhajeetdas/aptos-2019-jpg/versions/12/APTOS 2019 (Original) (Binary)/DR/image_3 (143).png\n",
            " - /root/.cache/kagglehub/datasets/subhajeetdas/aptos-2019-jpg/versions/12/APTOS 2019 (Original) (Binary)/DR/image_3 (124).png\n",
            " - /root/.cache/kagglehub/datasets/subhajeetdas/aptos-2019-jpg/versions/12/APTOS 2019 (Original) (Binary)/No DR/image_01004.png\n",
            " - /root/.cache/kagglehub/datasets/subhajeetdas/aptos-2019-jpg/versions/12/APTOS 2019 (Original) (Binary)/DR/image_00701.png\n",
            " - /root/.cache/kagglehub/datasets/subhajeetdas/aptos-2019-jpg/versions/12/APTOS 2019 (Original) (Binary)/DR/image_01478.png\n",
            " - /root/.cache/kagglehub/datasets/subhajeetdas/aptos-2019-jpg/versions/12/APTOS 2019 (Original) (Binary)/No DR/image_02212.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
            "DenseNet121_model_fp16.tflite: 100%|██████████| 10/10 [00:22<00:00,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Average Inference Time (Quantized TFLite) =====\n",
            "Model              : DenseNet121_model_fp16.tflite\n",
            "Model size (MB)    : 14.855\n",
            "Input shape/dtype  : [1, 256, 256, 3] / <class 'numpy.float32'>\n",
            "Images evaluated   : 10\n",
            "Avg per image (ms) : 2181.291\n",
            "Median (ms)        : 1933.780\n",
            "P95 (ms)           : 3336.351\n",
            "Min/Max (ms)       : 1757.277 / 3597.289\n",
            "Approx FPS         : 0.46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# Robust AIT (Average Inference Time) for ONE quantized TFLite model on 10 images\n",
        "# - If test.csv has bad paths, it FALLS BACK to Kaggle APTOS images automatically.\n",
        "# - Works for FP16/INT8/FP32 TFLite.\n",
        "# ============================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, time, glob, numpy as np, pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "\n",
        "# ========= USER CONFIG =========\n",
        "MODEL_PATH = \"/content/drive/MyDrive/DiabeticProject/tflite/DenseNet121_model_fp16.tflite\"  # <-- change if needed\n",
        "LIMIT_IMAGES = 10\n",
        "WARMUP_RUNS = 5\n",
        "NUM_THREADS = 4\n",
        "FALLBACK_KAGGLE_DATASET = \"subhajeetdas/aptos-2019-jpg\"  # used only if test.csv is missing/broken\n",
        "TEST_CSV = \"/content/drive/MyDrive/DiabeticProject/test.csv\"\n",
        "# ==============================\n",
        "\n",
        "def file_mb(path):\n",
        "    try: return round(os.path.getsize(path)/(1024*1024), 3)\n",
        "    except: return None\n",
        "\n",
        "def get_preprocess_from_name(model_path):\n",
        "    name = os.path.basename(model_path).lower()\n",
        "    f = lambda x: x / 255.0\n",
        "    if \"efficientnetv2\" in name or \"efficientnetv2b0\" in name:\n",
        "        f = tf.keras.applications.efficientnet_v2.preprocess_input\n",
        "    elif \"inceptionv3\" in name:\n",
        "        f = tf.keras.applications.inception_v3.preprocess_input\n",
        "    elif \"mobilenetv2\" in name:\n",
        "        f = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "    elif \"resnet50v2\" in name or \"resnetv2\" in name:\n",
        "        f = tf.keras.applications.resnet_v2.preprocess_input\n",
        "    elif \"nasnetmobile\" in name or \"nasnet\" in name:\n",
        "        f = tf.keras.applications.nasnet.preprocess_input\n",
        "    elif \"densenet121\" in name or \"densenet\" in name:\n",
        "        f = tf.keras.applications.densenet.preprocess_input\n",
        "    return f\n",
        "\n",
        "def quantize_np(x_float, scale, zp, dtype):\n",
        "    if scale is None or scale == 0:\n",
        "        return x_float.astype(dtype)\n",
        "    q = np.round(x_float / scale + zp)\n",
        "    if np.issubdtype(dtype, np.integer):\n",
        "        info = np.iinfo(dtype); q = np.clip(q, info.min, info.max)\n",
        "    return q.astype(dtype)\n",
        "\n",
        "def load_and_prep(path, target_hw, preprocess_fn):\n",
        "    img = Image.open(path).convert(\"RGB\").resize(target_hw, Image.BILINEAR)\n",
        "    x = np.array(img, dtype=np.float32)\n",
        "    x = preprocess_fn(x)\n",
        "    return np.expand_dims(x, 0)\n",
        "\n",
        "def pick_10_image_paths(test_csv_path, fallback_dataset):\n",
        "    # 1) Try test.csv\n",
        "    if os.path.exists(test_csv_path):\n",
        "        try:\n",
        "            df = pd.read_csv(test_csv_path)\n",
        "            if \"filepath\" in df.columns:\n",
        "                df = df[df[\"filepath\"].apply(os.path.exists)]\n",
        "                if len(df) >= 1:\n",
        "                    return df.sample(n=min(LIMIT_IMAGES, len(df)), random_state=42)[\"filepath\"].tolist()\n",
        "        except Exception:\n",
        "            pass  # fall through to kagglehub\n",
        "    # 2) Fallback: Kaggle APTOS dataset\n",
        "    try:\n",
        "        import kagglehub\n",
        "        dpath = kagglehub.dataset_download(fallback_dataset)\n",
        "        imgs = sorted(glob.glob(os.path.join(dpath, \"**\", \"*.png\"), recursive=True))\n",
        "        if not imgs:\n",
        "            imgs = sorted(glob.glob(os.path.join(dpath, \"**\", \"*.jpg\"), recursive=True))\n",
        "        if not imgs:\n",
        "            raise FileNotFoundError(\"No images found in Kaggle fallback.\")\n",
        "        rng = np.random.default_rng(42)\n",
        "        idx = rng.choice(len(imgs), size=min(LIMIT_IMAGES, len(imgs)), replace=False)\n",
        "        return [imgs[i] for i in idx]\n",
        "    except Exception as e:\n",
        "        raise FileNotFoundError(\n",
        "            \"No usable images. Fix paths in test.csv or ensure Kaggle dataset can be downloaded.\\n\"\n",
        "            f\"Original error: {e}\"\n",
        "        )\n",
        "\n",
        "def average_inference_time_tflite(model_path, image_paths):\n",
        "    interpreter = tf.lite.Interpreter(model_path=model_path, num_threads=NUM_THREADS)\n",
        "    interpreter.allocate_tensors()\n",
        "    in_det = interpreter.get_input_details()[0]\n",
        "    out_det = interpreter.get_output_details()[0]\n",
        "\n",
        "    _, H, W, C = in_det[\"shape\"]\n",
        "    in_dtype = in_det[\"dtype\"]\n",
        "    in_scale, in_zp = in_det.get(\"quantization\", (None, None))\n",
        "\n",
        "    preprocess_fn = get_preprocess_from_name(model_path)\n",
        "\n",
        "    # Warm-up\n",
        "    dummy = np.zeros((1, H, W, C), dtype=np.float32)\n",
        "    dummy = preprocess_fn(dummy)\n",
        "    dummy_q = quantize_np(dummy, in_scale, in_zp, in_dtype) if in_dtype != np.float32 else dummy.astype(in_dtype)\n",
        "    interpreter.set_tensor(in_det[\"index\"], dummy_q)\n",
        "    for _ in range(max(0, WARMUP_RUNS)):\n",
        "        interpreter.invoke(); _ = interpreter.get_tensor(out_det[\"index\"])\n",
        "\n",
        "    # Timing\n",
        "    times = []\n",
        "    for p in tqdm(image_paths, desc=os.path.basename(model_path)):\n",
        "        x = load_and_prep(p, (W, H), preprocess_fn)\n",
        "        x = quantize_np(x, in_scale, in_zp, in_dtype) if in_dtype != np.float32 else x.astype(in_dtype)\n",
        "        interpreter.set_tensor(in_det[\"index\"], x)\n",
        "        t0 = time.perf_counter(); interpreter.invoke(); t1 = time.perf_counter()\n",
        "        _ = interpreter.get_tensor(out_det[\"index\"])\n",
        "        times.append((t1 - t0) * 1000.0)\n",
        "\n",
        "    times = np.array(times, dtype=np.float64)\n",
        "    return {\n",
        "        \"model_path\": model_path,\n",
        "        \"images\": len(image_paths),\n",
        "        \"input_shape\": [int(d) for d in in_det[\"shape\"]],\n",
        "        \"input_dtype\": str(in_dtype),\n",
        "        \"tflite_size_mb\": file_mb(model_path),\n",
        "        \"avg_ms\": float(times.mean()),\n",
        "        \"median_ms\": float(np.median(times)),\n",
        "        \"p95_ms\": float(np.percentile(times, 95)),\n",
        "        \"min_ms\": float(times.min()),\n",
        "        \"max_ms\": float(times.max()),\n",
        "        \"fps\": float(1000.0 / times.mean()) if times.mean() > 0 else None,\n",
        "    }\n",
        "\n",
        "# ---------- run ----------\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    raise FileNotFoundError(f\"TFLite model not found: {MODEL_PATH}\")\n",
        "\n",
        "image_paths = pick_10_image_paths(TEST_CSV, FALLBACK_KAGGLE_DATASET)\n",
        "print(\"Images to evaluate:\")\n",
        "for p in image_paths: print(\" -\", p)\n",
        "\n",
        "res = average_inference_time_tflite(MODEL_PATH, image_paths)\n",
        "\n",
        "print(\"\\n===== Average Inference Time (Quantized TFLite) =====\")\n",
        "print(f\"Model              : {os.path.basename(res['model_path'])}\")\n",
        "print(f\"Model size (MB)    : {res['tflite_size_mb']}\")\n",
        "print(f\"Input shape/dtype  : {res['input_shape']} / {res['input_dtype']}\")\n",
        "print(f\"Images evaluated   : {res['images']}\")\n",
        "print(f\"Avg per image (ms) : {res['avg_ms']:.3f}\")\n",
        "print(f\"Median (ms)        : {res['median_ms']:.3f}\")\n",
        "print(f\"P95 (ms)           : {res['p95_ms']:.3f}\")\n",
        "print(f\"Min/Max (ms)       : {res['min_ms']:.3f} / {res['max_ms']:.3f}\")\n",
        "print(f\"Approx FPS         : {res['fps']:.2f}\")\n"
      ]
    }
  ]
}