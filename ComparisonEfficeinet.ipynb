{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOuOlyP1IQmUVJGQarhzDJ9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manushi0304/Diabetic_Retinopathy/blob/main/ComparisonEfficeinet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLDqz5mSQ8bI",
        "outputId": "96cee99a-920f-4ed2-c854-abe3b9573d51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "===== BASELINE (EfficientNetV2B0) =====\n",
            "Base FP16 TFLite       : 12.943 MB  (EfficientNetV2B0_model_fp16.tflite)\n",
            "Remove FP16 Dense(d×C) : -0.012 MB [d=1280, C=5, dtype=float16]\n",
            "Backbone-only (est.)   :  12.931 MB\n",
            "\n",
            "===== HYBRID SIZE via REPLACE (each head) — EfficientNetV2B0 =====\n",
            "\n",
            "REPLACE → Linear SVM\n",
            "Backbone-only (est.)   : 12.931 MB\n",
            "(+) Head               : 0.024 MB\n",
            "(+) Preprocessing      : 0.010 MB\n",
            "TOTAL                     : 12.965 MB\n",
            "\n",
            "REPLACE → RBF SVM\n",
            "Backbone-only (est.)   : 12.931 MB\n",
            "(+) Head               : 2.941 MB\n",
            "(+) Preprocessing      : 0.010 MB\n",
            "TOTAL                     : 15.881 MB\n",
            "\n",
            "REPLACE → Random Forest\n",
            "Backbone-only (est.)   : 12.931 MB\n",
            "(+) Head               : 1.559 MB\n",
            "(+) Preprocessing      : 0.010 MB\n",
            "TOTAL                     : 14.500 MB\n",
            "\n",
            "REPLACE → kNN\n",
            "Backbone-only (est.)   : 12.931 MB\n",
            "(+) Head               : 19.539 MB\n",
            "(+) Preprocessing      : 0.010 MB\n",
            "TOTAL                     : 32.479 MB\n",
            "\n",
            "[saved] /content/drive/MyDrive/DiabeticProject/saved_models/hybrid_size_replace_allheads_effv2b0.csv\n",
            "\n",
            "Notes:\n",
            "- These totals use REPLACE arithmetic: (base - FP16 Dense head) + head (+ shared preproc).\n",
            "- The removed head is ~0.013 MB for d=1280, C=5 (tiny), so totals stay close to base FP16.\n",
            "- To get totals significantly < base FP16, use an INT8 backbone or a smaller/pruned network.\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# REPLACE arithmetic for ALL heads:\n",
        "# (Base FP16 TFLite - built-in FP16 Dense head) + head (+ preproc)\n",
        "# Model: EfficientNetV2B0 (penultimate d=1280), C=5\n",
        "# Heads covered: Linear SVM, RBF SVM, Random Forest, kNN\n",
        "# ==========================================\n",
        "\n",
        "# 0) Mount (safe to re-run)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import os, csv\n",
        "from pathlib import Path\n",
        "\n",
        "# ===== 1) CONFIG =====\n",
        "# Path to your EfficientNetV2B0 FP16 TFLite (or fallback MB will be used)\n",
        "TFLITE_PATH = \"/content/drive/MyDrive/DiabeticProject/tflite/EfficientNetV2B0_model_fp16.tflite\"  # <- change if needed\n",
        "BASE_MB_FALLBACK = 12.3     # used only if TFLITE_PATH doesn't exist (approx FP16 size)\n",
        "\n",
        "# Built-in head details to remove (Dense(d×C)+bias in FP16)\n",
        "d = 1280    # feature dimension from EfficientNetV2B0 penultimate layer\n",
        "C = 5       # number of classes\n",
        "HEAD_DTYPE = \"float16\"  # built-in head dtype inside FP16 TFLite\n",
        "\n",
        "# External head params\n",
        "# SVM / RF / kNN knobs\n",
        "N = 8000               # kNN: stored feature vectors\n",
        "m = 1200               # RBF-SVM: total support vectors across OvR/OvO\n",
        "T = 100                # RandomForest: number of trees\n",
        "nodes_per_tree = 511   # avg nodes per tree\n",
        "\n",
        "# Preprocessing (count once per scenario)\n",
        "INCLUDE_SCALER = True\n",
        "INCLUDE_PCA    = False\n",
        "d_pca          = 256   # only used if INCLUDE_PCA=True\n",
        "\n",
        "# Dtypes for external heads\n",
        "EXT_EMB_DTYPE  = \"float16\"  # embeddings/support vectors storage (kNN/RBF-SVM)\n",
        "EXT_WTS_DTYPE  = \"float32\"  # linear SVM weights & biases\n",
        "LABEL_BYTES    = 1\n",
        "\n",
        "# Output CSV path\n",
        "OUT_CSV = \"/content/drive/MyDrive/DiabeticProject/saved_models/hybrid_size_replace_allheads_effv2b0.csv\"\n",
        "\n",
        "# ===== 2) Helpers =====\n",
        "def bytes_per_float(dtype:str)->int:\n",
        "    x = dtype.lower()\n",
        "    if x in (\"float16\",\"fp16\",\"half\"): return 2\n",
        "    if x in (\"float32\",\"fp32\",\"single\"): return 4\n",
        "    if x in (\"float64\",\"fp64\",\"double\"): return 8\n",
        "    raise ValueError(f\"Unsupported dtype: {dtype}\")\n",
        "\n",
        "def size_mb(nbytes:int)->float:\n",
        "    return nbytes / (1024.0 * 1024.0)\n",
        "\n",
        "def get_base_mb(path:str|None, fallback_mb:float)->float:\n",
        "    if path and os.path.exists(path):\n",
        "        return os.path.getsize(path) / (1024.0*1024.0)\n",
        "    return fallback_mb\n",
        "\n",
        "# Built-in Dense(d×C)+bias to REMOVE (assume head stored in FP16)\n",
        "def builtin_dense_head_bytes(d:int, C:int, head_dtype:str)->int:\n",
        "    bpf = bytes_per_float(head_dtype)\n",
        "    return (d*C + C) * bpf\n",
        "\n",
        "# External heads to ADD\n",
        "def scaler_bytes(d:int)->int:\n",
        "    # mean + std (float32)\n",
        "    return 2 * d * bytes_per_float(\"float32\")\n",
        "\n",
        "def pca_bytes(d_orig:int, d_pca:int)->int:\n",
        "    # components(d_pca x d_orig) + mean(d_orig) as float32\n",
        "    bf = bytes_per_float(\"float32\")\n",
        "    return d_pca*d_orig*bf + d_orig*bf\n",
        "\n",
        "def linear_svm_ovr_bytes(C:int, d:int, dtype:str=\"float32\")->int:\n",
        "    bf = bytes_per_float(dtype)\n",
        "    return (C*d + C) * bf  # W + b\n",
        "\n",
        "def rbf_svm_bytes(m:int, d:int, C:int, sv_dtype:str=\"float32\")->int:\n",
        "    bf = bytes_per_float(sv_dtype)\n",
        "    # support vectors + dual coeffs (OvR approx m*C) + biases(C)\n",
        "    return m*d*bf + m*C*bf + C*bf\n",
        "\n",
        "def knn_bytes(N:int, d:int, emb_dtype:str=\"float16\", label_bytes:int=1)->int:\n",
        "    bf = bytes_per_float(emb_dtype)\n",
        "    return N*d*bf + N*label_bytes\n",
        "\n",
        "def random_forest_bytes(T:int, nodes_per_tree:int, bytes_per_node:int=32)->int:\n",
        "    return T * nodes_per_tree * bytes_per_node\n",
        "\n",
        "# ===== 3) Base and \"backbone-only\" via subtraction =====\n",
        "base_mb = get_base_mb(TFLITE_PATH, BASE_MB_FALLBACK)\n",
        "head_rm_mb = size_mb(builtin_dense_head_bytes(d, C, HEAD_DTYPE))\n",
        "backbone_only_mb = max(0.0, base_mb - head_rm_mb)\n",
        "\n",
        "print(\"===== BASELINE (EfficientNetV2B0) =====\")\n",
        "print(f\"Base FP16 TFLite       : {base_mb:.3f} MB  ({Path(TFLITE_PATH).name if os.path.exists(TFLITE_PATH) else 'fallback'})\")\n",
        "print(f\"Remove FP16 Dense(d×C) : -{head_rm_mb:.3f} MB [d={d}, C={C}, dtype={HEAD_DTYPE}]\")\n",
        "print(f\"Backbone-only (est.)   :  {backbone_only_mb:.3f} MB\")\n",
        "\n",
        "# Preprocessing shared term\n",
        "prep_bytes = 0\n",
        "if INCLUDE_SCALER:\n",
        "    prep_bytes += scaler_bytes(d)\n",
        "if INCLUDE_PCA:\n",
        "    prep_bytes += pca_bytes(d, d_pca)\n",
        "prep_mb = size_mb(prep_bytes)\n",
        "\n",
        "# ===== 4) Scenarios: each head separately (REPLACE arithmetic) =====\n",
        "scenarios = []\n",
        "\n",
        "def add_scenario(name, add_bytes):\n",
        "    total_mb = backbone_only_mb + size_mb(add_bytes + (prep_bytes if add_bytes>0 else 0))\n",
        "    scenarios.append({\n",
        "        \"scenario\": name,\n",
        "        \"base_fp16_mb\": round(base_mb, 6),\n",
        "        \"removed_head_mb\": round(head_rm_mb, 6),\n",
        "        \"backbone_only_mb\": round(backbone_only_mb, 6),\n",
        "        \"head_mb\": round(size_mb(add_bytes), 6),\n",
        "        \"preproc_mb\": round(prep_mb if add_bytes>0 else 0.0, 6),\n",
        "        \"total_mb\": round(total_mb, 6),\n",
        "        \"d\": d, \"C\": C, \"N\": N, \"m\": m, \"T\": T, \"nodes_per_tree\": nodes_per_tree,\n",
        "        \"head_dtype_removed\": HEAD_DTYPE,\n",
        "        \"ext_emb_dtype\": EXT_EMB_DTYPE,\n",
        "        \"ext_wts_dtype\": EXT_WTS_DTYPE,\n",
        "        \"include_scaler\": INCLUDE_SCALER,\n",
        "        \"include_pca\": INCLUDE_PCA,\n",
        "        \"tflite_path\": TFLITE_PATH if os.path.exists(TFLITE_PATH) else \"(fallback)\",\n",
        "    })\n",
        "\n",
        "# Linear SVM\n",
        "lin_bytes = linear_svm_ovr_bytes(C, d, dtype=EXT_WTS_DTYPE)\n",
        "add_scenario(\"REPLACE → Linear SVM\", lin_bytes)\n",
        "\n",
        "# RBF SVM\n",
        "rbf_bytes = rbf_svm_bytes(m, d, C, sv_dtype=EXT_EMB_DTYPE)\n",
        "add_scenario(\"REPLACE → RBF SVM\", rbf_bytes)\n",
        "\n",
        "# Random Forest\n",
        "rf_bytes = random_forest_bytes(T, nodes_per_tree, 32)\n",
        "add_scenario(\"REPLACE → Random Forest\", rf_bytes)\n",
        "\n",
        "# kNN\n",
        "knn_b = knn_bytes(N, d, emb_dtype=EXT_EMB_DTYPE, label_bytes=LABEL_BYTES)\n",
        "add_scenario(\"REPLACE → kNN\", knn_b)\n",
        "\n",
        "# ===== 5) Print nicely =====\n",
        "print(\"\\n===== HYBRID SIZE via REPLACE (each head) — EfficientNetV2B0 =====\")\n",
        "for s in scenarios:\n",
        "    print(f\"\\n{s['scenario']}\")\n",
        "    print(f\"Backbone-only (est.)   : {s['backbone_only_mb']:.3f} MB\")\n",
        "    print(f\"(+) Head               : {s['head_mb']:.3f} MB\")\n",
        "    if s['head_mb'] > 0:\n",
        "        print(f\"(+) Preprocessing      : {s['preproc_mb']:.3f} MB\")\n",
        "    print(f\"{'TOTAL':25} : {s['total_mb']:.3f} MB\")\n",
        "\n",
        "# ===== 6) Save CSV =====\n",
        "os.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)\n",
        "with open(OUT_CSV, \"w\", newline=\"\") as f:\n",
        "    writer = csv.DictWriter(f, fieldnames=list(scenarios[0].keys()))\n",
        "    writer.writeheader()\n",
        "    writer.writerows(scenarios)\n",
        "print(f\"\\n[saved] {OUT_CSV}\")\n",
        "\n",
        "print(\"\\nNotes:\")\n",
        "print(\"- These totals use REPLACE arithmetic: (base - FP16 Dense head) + head (+ shared preproc).\")\n",
        "print(\"- The removed head is ~0.013 MB for d=1280, C=5 (tiny), so totals stay close to base FP16.\")\n",
        "print(\"- To get totals significantly < base FP16, use an INT8 backbone or a smaller/pruned network.\")\n"
      ]
    }
  ]
}