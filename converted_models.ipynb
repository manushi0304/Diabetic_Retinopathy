{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manushi0304/Diabetic_Retinopathy/blob/main/converted_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Robust CM for TFLite FP16 DenseNet121 (tolerates wrong extensions / missing files) ---\n",
        "import os, itertools, warnings\n",
        "from pathlib import Path\n",
        "import numpy as np, pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Reuse discovered paths from your previous cell:\n",
        "# CSV_PATH = \"drive/MyDrive/DiabeticProject/test.csv\"\n",
        "# TFLITE_PATH = \"drive/MyDrive/DiabeticProject/tflite/DenseNet121_model_fp16.tflite\"\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "NUM_THREADS = max(1, min(4, os.cpu_count() or 1))\n",
        "TRY_EXTS = [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"]\n",
        "SKIP_MISSING = True  # set False to raise if any image is not found\n",
        "\n",
        "def _coerce_label(x):\n",
        "    if isinstance(x, (np.integer, int)): return int(x)\n",
        "    if isinstance(x, str):\n",
        "        s = x.strip().lower()\n",
        "        mapping = {\"no_dr\":0,\"no dr\":0,\"normal\":0,\"0\":0,\"dr\":1,\"referable_dr\":1,\"referable dr\":1,\"1\":1}\n",
        "        if s in mapping: return mapping[s]\n",
        "        try: return int(float(s))\n",
        "        except: pass\n",
        "    raise ValueError(f\"Cannot coerce label '{x}' to int 0/1.\")\n",
        "\n",
        "def _fix_path_if_missing(p):\n",
        "    \"\"\"If path p doesn't exist, try alternate extensions and a fuzzy stem search.\"\"\"\n",
        "    if os.path.exists(p):\n",
        "        return p\n",
        "    base, ext = os.path.splitext(p)\n",
        "    # Try swapping extension\n",
        "    for e in TRY_EXTS:\n",
        "        q = base + e\n",
        "        if os.path.exists(q):\n",
        "            return q\n",
        "    # Fuzzy search by stem in the same directory\n",
        "    parent = Path(p).parent\n",
        "    stem = Path(p).stem\n",
        "    if parent.exists():\n",
        "        cands = list(parent.glob(stem + \"*\"))\n",
        "        # prefer image files\n",
        "        cands = [str(c) for c in cands if c.suffix.lower() in TRY_EXTS]\n",
        "        if cands:\n",
        "            return cands[0]\n",
        "    return None\n",
        "\n",
        "def load_csv_and_paths(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    cols = {c.lower(): c for c in df.columns}\n",
        "    label_col = next((cols[c] for c in [\"label\",\"labels\",\"diagnosis\",\"target\",\"y\"] if c in cols), None)\n",
        "    if label_col is None:\n",
        "        raise ValueError(f\"No label column found in {list(df.columns)}\")\n",
        "\n",
        "    path_col = cols.get(\"filepath\", cols.get(\"path\"))\n",
        "    id_col = cols.get(\"id_code\", cols.get(\"image\", cols.get(\"id\")))\n",
        "\n",
        "    if path_col is None and id_col is None:\n",
        "        raise ValueError(\"CSV must have either a filepath/path column or an id_code/image/id column.\")\n",
        "\n",
        "    img_paths, labels = [], []\n",
        "    missing = 0\n",
        "\n",
        "    if path_col is not None:\n",
        "        for _, r in df.iterrows():\n",
        "            p = str(r[path_col])\n",
        "            if not os.path.isabs(p):\n",
        "                p = str((Path(csv_path).parent / p).resolve())\n",
        "            q = _fix_path_if_missing(p)\n",
        "            if q is None:\n",
        "                missing += 1\n",
        "                if not SKIP_MISSING:\n",
        "                    raise FileNotFoundError(f\"Image not found: {p}\")\n",
        "                continue\n",
        "            img_paths.append(q)\n",
        "            labels.append(_coerce_label(r[label_col]))\n",
        "    else:\n",
        "        # id_code mode -> try common folders near CSV\n",
        "        csv_dir = Path(csv_path).parent\n",
        "        cand_dirs = [\n",
        "            csv_dir/\"images\"/\"test\", csv_dir/\"images\"/\"val\", csv_dir/\"images\",\n",
        "            csv_dir/\"data\"/\"images\"/\"test\", csv_dir/\"data\"/\"test\", csv_dir/\"data\"\n",
        "        ]\n",
        "        cand_dirs = [d for d in cand_dirs if d.exists()]\n",
        "        if not cand_dirs:\n",
        "            raise FileNotFoundError(\"Could not infer images directory for id_code; create one near the CSV.\")\n",
        "        for _, r in df.iterrows():\n",
        "            pid = str(r[id_col]).strip()\n",
        "            q = None\n",
        "            for d in cand_dirs:\n",
        "                for e in TRY_EXTS:\n",
        "                    t = d / f\"{pid}{e}\"\n",
        "                    if t.exists():\n",
        "                        q = str(t); break\n",
        "                if q: break\n",
        "            if q is None:\n",
        "                missing += 1\n",
        "                if not SKIP_MISSING:\n",
        "                    raise FileNotFoundError(f\"No image for id '{pid}' in {cand_dirs}\")\n",
        "                continue\n",
        "            img_paths.append(q)\n",
        "            labels.append(_coerce_label(r[label_col]))\n",
        "\n",
        "    if missing:\n",
        "        print(f\"[Warning] Skipped {missing} rows with missing images; proceeding with {len(img_paths)} samples.\")\n",
        "    return img_paths, labels\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    img = Image.open(path).convert(\"RGB\").resize(IMG_SIZE, Image.BILINEAR)\n",
        "    arr = np.asarray(img, dtype=np.float32)\n",
        "    arr = densenet_preprocess(arr)\n",
        "    return np.expand_dims(arr, 0)\n",
        "\n",
        "class TFLiteModel:\n",
        "    def __init__(self, model_path, threads=NUM_THREADS):\n",
        "        self.interp = tf.lite.Interpreter(model_path=model_path, num_threads=threads)\n",
        "        self.interp.allocate_tensors()\n",
        "        self.inp = self.interp.get_input_details()[0]['index']\n",
        "        self.out = self.interp.get_output_details()[0]['index']\n",
        "    def predict_one(self, x):\n",
        "        self.interp.set_tensor(self.inp, x)\n",
        "        self.interp.invoke()\n",
        "        return self.interp.get_tensor(self.out)\n",
        "\n",
        "def decide_binary_preds(outputs):\n",
        "    outputs = np.asarray(outputs)\n",
        "    if outputs.ndim == 1: outputs = outputs.reshape(-1, 1)\n",
        "    if outputs.shape[1] == 1:\n",
        "        probs1 = 1/(1+np.exp(-outputs.squeeze()))\n",
        "        preds = (probs1 >= 0.5).astype(int)\n",
        "        return preds, probs1\n",
        "    elif outputs.shape[1] == 2:\n",
        "        logits = outputs - outputs.max(1, keepdims=True)\n",
        "        probs = np.exp(logits) / np.exp(logits).sum(1, keepdims=True)\n",
        "        return probs.argmax(1), probs[:,1]\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected output shape {outputs.shape}\")\n",
        "\n",
        "def plot_confusion_matrix(cm, classes=(0,1), title=\"Confusion Matrix\", save_path=\"confusion_matrix_tflite.png\"):\n",
        "    plt.figure(figsize=(5, 4.5), dpi=120)\n",
        "    plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "    plt.title(title); plt.colorbar()\n",
        "    ticks = np.arange(len(classes))\n",
        "    plt.xticks(ticks, classes); plt.yticks(ticks, classes)\n",
        "    plt.xlabel(\"Predicted label\"); plt.ylabel(\"True label\")\n",
        "    thresh = cm.max()/2 if cm.max()>0 else 0.5\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, f\"{cm[i,j]:d}\", ha=\"center\",\n",
        "                     color=\"white\" if cm[i,j] > thresh else \"black\",\n",
        "                     fontsize=12, fontweight=\"bold\")\n",
        "    plt.tight_layout(); plt.savefig(save_path, bbox_inches=\"tight\"); plt.close()\n",
        "    print(f\"[Saved] {save_path}\")\n",
        "\n",
        "# ---- Run ----\n",
        "print(\"Loading CSV and resolving image paths...\")\n",
        "img_paths, y_true = load_csv_and_paths(CSV_PATH)\n",
        "y_true = np.array(y_true, dtype=int)\n",
        "print(f\"Using {len(img_paths)} images for evaluation.\")\n",
        "\n",
        "print(\"Loading TFLite model...\")\n",
        "model = TFLITE_PATH\n",
        "interp = TFLiteModel(model)\n",
        "\n",
        "print(\"Running inference...\")\n",
        "outs = []\n",
        "for i, p in enumerate(img_paths, 1):\n",
        "    outs.append(interp.predict_one(load_and_preprocess_image(p)).squeeze())\n",
        "    if i % 100 == 0 or i == len(img_paths):\n",
        "        print(f\"Inferred {i}/{len(img_paths)}\")\n",
        "\n",
        "y_pred, _ = decide_binary_preds(np.array(outs))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "f1  = f1_score(y_true, y_pred, zero_division=0)\n",
        "print(f\"Accuracy:  {acc:.4f}\\nPrecision: {prec:.4f}\\nRecall:    {rec:.4f}\\nF1-score:  {f1:.4f}\")\n",
        "\n",
        "plot_confusion_matrix(cm, classes=(0,1), title=\"Confusion Matrix\", save_path=\"confusion_matrix_tflite.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHuOXZANQii7",
        "outputId": "03a19849-8ab3-4db3-d631-ca8b719c0926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CSV and resolving image paths...\n",
            "[Warning] Skipped 3662 rows with missing images; proceeding with 0 samples.\n",
            "Using 0 images for evaluation.\n",
            "Loading TFLite model...\n",
            "Running inference...\n",
            "Accuracy:  nan\n",
            "Precision: 0.0000\n",
            "Recall:    0.0000\n",
            "F1-score:  0.0000\n",
            "[Saved] confusion_matrix_tflite.png\n"
          ]
        }
      ]
    }
  ]
}